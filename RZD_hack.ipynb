{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3439a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from PIL import Image as Im\n",
    "from IPython.display import display, Image, clear_output\n",
    "from PIL import Image as Im\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4c1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\TORCH\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "from torchmetrics import F1Score as F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebc23cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) # фиксируем генератор случайных чисел\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed) # фиксируем заполнения хешей\n",
    "    np.random.seed(seed) # фиксируем генератор случайных чисел numpy\n",
    "    torch.manual_seed(seed) # фиксируем генератор случайных чисел pytorch\n",
    "    torch.cuda.manual_seed(seed) # фиксируем генератор случайных чисел для GPU\n",
    "    torch.backends.cudnn.benchmark = True #включение cuDNN Autotuner\n",
    "    #отключение отладок\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "    torch.autograd.profiler.profile(False)\n",
    "    torch.autograd.profiler.emit_nvtx(False)\n",
    "seed_everything(42)\n",
    "device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcd108",
   "metadata": {},
   "source": [
    "# Потоковое чтение кадров с любой доступрнйо камеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88be4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0) #0 - выбрать любую доступную камеру..  \n",
    "# while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Применяем операции обработки кадра - переворачиваем его по вертикали\n",
    "#         frame = cv2.flip(frame, 1)\n",
    "\n",
    "#         # Отображаем кадр\n",
    "#         #display(Image.fromarray(frame)\n",
    "#cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46859241",
   "metadata": {},
   "source": [
    "Нарезка видео на кадры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eafdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Укажите путь к папке с видеофайлами\n",
    "# video_folder = r'I:\\Хакатоны\\Цифровой прорыв РЖД\\train_dataset_Безопасный маршрут\\боковая камера\\Новая папка'\n",
    "\n",
    "# # Укажите папку для сохранения кадров\n",
    "# output_folder = r'I:\\out1'\n",
    "\n",
    "# # Получаем список файлов в папке\n",
    "# video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
    "\n",
    "# # Создаем папку для сохранения кадров, если она не существует\n",
    "\n",
    "# out = 70\n",
    "# count = 70\n",
    "# # Цикл для обработки каждого видео\n",
    "# for video_file in tqdm(video_files):\n",
    "#     video_path = os.path.join(video_folder, video_file)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#     # Проверяем, успешно ли открылся видеофайл\n",
    "#     if cap.isOpened():\n",
    "#         print(f\"Открыт видеофайл {video_file}.\")\n",
    "\n",
    "#     frame_count = 0\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         if frame_count % int(cap.get(cv2.CAP_PROP_FPS)) == 0:\n",
    "\n",
    "#             frame_path = f'{output_folder}/{out:04d}_frame_{frame_count:04d}.png'\n",
    "            \n",
    "#             # Преобразуем кадр к размеру 224x224\n",
    "#             frame_resized = cv2.resize(frame, (224, 224))\n",
    "\n",
    "#             # Преобразуем кадр в RGB формат перед сохранением\n",
    "#             #frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "#             cv2.imwrite(frame_path, frame_resized)\n",
    "#             count +=1\n",
    "\n",
    "#         frame_count += 1\n",
    "#     out += 1\n",
    "#     cap.release()\n",
    "\n",
    "# print(f\"Всего сохранено кадров: {count}\")\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3f5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функиия преобразования фоток к нужному размеру\n",
    "def process_images_in_folder(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith('.png'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                try:\n",
    "                    with Im.open(file_path) as img:\n",
    "                        img = img.resize((224, 224), Im.ANTIALIAS)\n",
    "                        img.save(file_path)\n",
    "                        print(f\"Processed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Путь к корневой папке, в которой находятся ваши изображения\n",
    "#root_folder = r'I:\\Хакатоны\\Цифровой прорыв РЖД\\Новая папка'\n",
    "#process_images_in_folder(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd958b",
   "metadata": {},
   "source": [
    "Подбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b736763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>File Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Folder Name                                          File Path\n",
       "0           0  I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...\n",
       "1           0  I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...\n",
       "2           0  I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...\n",
       "3           0  I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0...\n",
       "4           0  I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим датест имеющих файлов\n",
    "# Разметка по классам:\n",
    "# 0-помехи отсутсвуют\n",
    "# 1- помехи отсутсвуют\n",
    "\n",
    "def create_dataframe(folder_path):\n",
    "    data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        \n",
    "        for file in files:\n",
    "            folder_name = os.path.basename(root)\n",
    "            file_path = os.path.join(root, file)\n",
    "            data.append((folder_name, file_path))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Folder Name', 'File Path'])\n",
    "    return df\n",
    "\n",
    "# Пример использования\n",
    "folder_path = r\"I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\"\n",
    "df = create_dataframe(folder_path)\n",
    "\n",
    "# Вывести первые несколько строк датафрейма\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5f1292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Folder Name'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b08c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Folder Name'] = df['Folder Name']\n",
    "df['Folder Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ba99b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Folder Name  File Path                                                          \n",
       "0            I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\0000_frame_0000.png     1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\╨д╨░╨╕╠Ж╨╗ 10757.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\╨д╨░╨╕╠Ж╨╗ 10745.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\╨д╨░╨╕╠Ж╨╗ 10746.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\╨д╨░╨╕╠Ж╨╗ 10747.png    1\n",
       "                                                                                   ..\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\0007_frame_37230.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\0007_frame_37260.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\0007_frame_37290.png    1\n",
       "             I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\0\\0007_frame_37320.png    1\n",
       "1            I:\\Хакатоны\\Цифровой прорыв РЖД\\Набор_кадров\\1\\╨д╨░╨╕╠Ж╨╗ 9.png        1\n",
       "Name: count, Length: 64488, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f0ebc",
   "metadata": {},
   "source": [
    "Параметры фцнкции обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5021f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #размер батча\n",
    "num_epochs = 10 #количество эпох\n",
    "lr = 0.001 #шаг оптимизатора\n",
    "num_classes = 2 #количество классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a2dde",
   "metadata": {},
   "source": [
    "Создадим датасет для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf61ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file_path, transform=None):\n",
    "        self.csv_data = csv_file_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_filename = self.csv_data.iloc[index, 1]\n",
    "        class_label = self.csv_data.iloc[index, 0]\n",
    "\n",
    "        # Полный путь к файлу изображения\n",
    "        image_path = os.path.join(image_filename)\n",
    "        image = Im.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(int(class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bccb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформации для изображений\n",
    "# data_transform = transforms.Compose([\n",
    "#     #transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Создание экземпляра датасета\n",
    "custom_dataset = CustomDataset(df, transform=data_transform)\n",
    "\n",
    "# Разделение на тренировочный и валидационный наборы с учетом дисбаланса классов\n",
    "validation_split = 0.2\n",
    "dataset_size = len(custom_dataset)\n",
    "validation_size = int(validation_split * dataset_size)\n",
    "train_size = dataset_size - validation_size\n",
    "\n",
    "# Получение индексов для разделения\n",
    "indices = list(range(dataset_size))\n",
    "random.shuffle(indices)  # Перемешиваем индексы перед разделением\n",
    "train_indices, validation_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# Создание DataLoader для тренировочного и валидационного наборов\n",
    "num_workers = torch.multiprocessing.cpu_count()  # Использование всех доступных ядер\n",
    "train_loader = DataLoader(custom_dataset, batch_size=batch_size, sampler=train_indices, pin_memory=True)\n",
    "valid_loader = DataLoader(custom_dataset, batch_size=batch_size, sampler=validation_indices, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee2a5d",
   "metadata": {},
   "source": [
    "Функция обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99dadcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader, valid_loader, device, lr):\n",
    "    model = model.to(device)\n",
    "    # Определение функции потерь и оптимизатора\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    f1_metric = F1(task=\"multiclass\", num_classes=num_classes).to(device)  # num_classes - количество классов\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()  # Засекаем время начала эпохи\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            # Обновляем метрику F1\n",
    "            f1_metric.update(predicted, labels)\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "        f1_metric.reset()  # Сбрасываем метрику для следующей эпохи\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "                # Обновляем метрику F1\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "                f1_metric.update(predicted, labels)\n",
    "\n",
    "        # Получаем значение F1-меры\n",
    "        f1_value = f1_metric.compute()\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} | Train_Loss: {running_loss / len(train_loader):.4f} | Valid_Loss: {valid_loss / len(valid_loader):.4f} | F1 Score: {f1_value:.4f} | Time: {epoch_duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21194e",
   "metadata": {},
   "source": [
    "# Архитектуры с предобученными весами\n",
    "\n",
    "## Архитектура EfficientNet\n",
    "\n",
    "Предобученая архитектура EfficientNet-B0 из библиотеки torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c601de9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train_Loss: 0.1434 | Valid_Loss: 0.1023 | F1 Score: 0.9700 | Time: 648.55 seconds\n",
      "Epoch 2 | Train_Loss: 0.0948 | Valid_Loss: 0.0706 | F1 Score: 0.9782 | Time: 596.04 seconds\n",
      "Epoch 3 | Train_Loss: 0.0796 | Valid_Loss: 0.0795 | F1 Score: 0.9751 | Time: 587.41 seconds\n",
      "Epoch 4 | Train_Loss: 0.0703 | Valid_Loss: 0.0638 | F1 Score: 0.9802 | Time: 597.98 seconds\n",
      "Epoch 5 | Train_Loss: 0.0655 | Valid_Loss: 0.0597 | F1 Score: 0.9822 | Time: 599.89 seconds\n",
      "Epoch 6 | Train_Loss: 0.0606 | Valid_Loss: 0.0571 | F1 Score: 0.9828 | Time: 604.15 seconds\n",
      "Epoch 7 | Train_Loss: 0.0567 | Valid_Loss: 0.0479 | F1 Score: 0.9849 | Time: 603.15 seconds\n",
      "Epoch 8 | Train_Loss: 0.0533 | Valid_Loss: 0.0553 | F1 Score: 0.9829 | Time: 599.64 seconds\n",
      "Epoch 9 | Train_Loss: 0.0501 | Valid_Loss: 0.0678 | F1 Score: 0.9815 | Time: 653.17 seconds\n",
      "Epoch 10 | Train_Loss: 0.0484 | Valid_Loss: 0.0482 | F1 Score: 0.9849 | Time: 633.12 seconds\n"
     ]
    }
   ],
   "source": [
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes, weights=\"EfficientNet_B0_Weights.IMAGENET1K_V1\"):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b0(weights=weights)\n",
    "        self.linear_layer = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.efficientnet(x)\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "\n",
    "efficient = EfficientNetB0()\n",
    "efficient = efficient.to(device)\n",
    "\n",
    "train_model(efficient, num_epochs, train_loader, valid_loader, device, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e1f6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем веса модели\n",
    "efficient = efficient.to('cpu')\n",
    "torch.save(efficient.state_dict(), 'efficient_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa435a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetB0(\n",
       "  (efficientnet): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=True)\n",
       "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузка весов модели\n",
    "efficient_train = EfficientNetB0()\n",
    "efficient_train.load_state_dict(torch.load('efficient_weights.pth'))\n",
    "efficient_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем словарь с весами\n",
    "#weights = efficient.state_dict()\n",
    "# Сохраняем словарь в файл\n",
    "#torch.save(weights, r'I:\\Хакатоны\\Цифровой прорыв РЖД\\Веса\\efficient_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aca702",
   "metadata": {},
   "source": [
    "Имитация работы системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e918f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficient_train\n",
    "def simulation_system(path, model):\n",
    "    # Инициализация переменных и шрифта\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "\n",
    "    # Измерение скорости считывания кадров\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    predicted = 0\n",
    "    frame_rate = 0\n",
    "    model.eval().to('cuda')\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Не удалось считать кадр. Возможно, поток закончился.\")\n",
    "            break\n",
    "        \n",
    "        if frame_count % int(cap.get(cv2.CAP_PROP_FPS)) == 0:\n",
    "            \n",
    "            frame_resized = cv2.resize(frame, (224, 224))\n",
    "            input_frame = transform(frame_resized)\n",
    "            # Добавьте размерность батча\n",
    "            input_frame = input_frame.unsqueeze(0).to('cuda')\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_frame)\n",
    "                predicted = torch.argmax(outputs).to('cpu').item()   \n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Вычисление и вывод скорости считывания кадров\n",
    "        if frame_count % 10 == 0:\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            frame_rate = 10 / elapsed_time  # Обновлять каждые 10 кадров\n",
    "            start_time = end_time\n",
    "        \n",
    "        font_color = (0, 0, 255)  # Reed color in BGR    \n",
    "        text = f'Class {str(predicted)} | FPS: {frame_rate:.2f}'\n",
    "        cv2.putText(frame, text, (30, 30), font, font_scale, font_color, font_thickness)\n",
    "\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        img = Image(data=buffer)\n",
    "        display(img)\n",
    "        clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e62f621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не удалось считать кадр. Возможно, поток закончился.\n"
     ]
    }
   ],
   "source": [
    "path = 'I://00_21_23short.mp4'\n",
    "simulation_system(path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6be729",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4e6694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_1_after_0(lst):\n",
    "    result = []\n",
    "    found_0 = False\n",
    "\n",
    "    for i, num in enumerate(lst):\n",
    "        if num == 0:\n",
    "            found_0 = True\n",
    "        elif num == 1 and found_0:\n",
    "            result.append(i)\n",
    "            found_0 = False\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def seconds_to_mmss(seconds):\n",
    "    minutes = seconds // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{minutes:02d}:{seconds:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "147c9853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca8d3aae8b047adbb3e4ce4f16894da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cases_count</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_08_36.mp4</td>\n",
       "      <td>37</td>\n",
       "      <td>[09:06, 33:23, 60:03, 60:08, 60:12, 60:17, 60:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00_20_12.mp4</td>\n",
       "      <td>39</td>\n",
       "      <td>[18:36, 19:33, 20:54, 21:08, 21:55, 22:38, 22:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_33_43.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>[72:08, 72:21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename cases_count                                         timestamps\n",
       "0  00_08_36.mp4          37  [09:06, 33:23, 60:03, 60:08, 60:12, 60:17, 60:...\n",
       "1  00_20_12.mp4          39  [18:36, 19:33, 20:54, 21:08, 21:55, 22:38, 22:...\n",
       "2  01_33_43.mp4           2                                     [72:08, 72:21]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Укажите путь к папке с видеофайлами\n",
    "video_folder = r'I:\\Хакатоны\\Цифровой прорыв РЖД\\test'\n",
    "# наименование модели\n",
    "model = efficient\n",
    "\n",
    "def simulation_system(video_folder, model):\n",
    "        df_sub = pd.DataFrame(columns=['filename', 'cases_count', 'timestamps'])\n",
    "        # Получаем список файлов в папке\n",
    "        video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
    "        # Цикл для обработки каждого видео\n",
    "        for video_file in tqdm(video_files):\n",
    "            video_path = os.path.join(video_folder, video_file)\n",
    "            lst = []\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = 0         \n",
    "\n",
    "            model.eval().to('cuda')\n",
    "\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "            while True:\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                if frame_count % int(cap.get(cv2.CAP_PROP_FPS)) == 0:\n",
    "\n",
    "                    frame_resized = cv2.resize(frame, (224, 224))\n",
    "                    input_frame = transform(frame_resized)\n",
    "                    # Добавьте размерность батча\n",
    "                    input_frame = input_frame.unsqueeze(0).to('cuda')\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(input_frame)\n",
    "                        predicted = torch.argmax(outputs).to('cpu').item()   \n",
    "                        \n",
    "                        lst.append(predicted)\n",
    "            \n",
    "\n",
    "            lst_time = [seconds_to_mmss(seconds) for seconds in find_first_1_after_0(lst)]\n",
    "            new_row = [video_file, len(lst_time), lst_time]\n",
    "            df_sub = pd.concat([df_sub, pd.DataFrame([new_row],columns=['filename', 'cases_count', 'timestamps'])], ignore_index=True)\n",
    " \n",
    "        return df_sub            \n",
    "\n",
    "\n",
    "sub = simulation_system(video_folder, model)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
